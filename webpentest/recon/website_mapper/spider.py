import requests
from bs4 import BeautifulSoup  # bs4 import Beautiful soup class
from urllib.parse import urljoin  # from urllib.parse module import urljoin class
#  first program get all the links in a html page
target_url = "https://zsecurity.org"
link = []


def extract_links(url):
    response = requests.get(url)
    response_content = response.content
    parser = BeautifulSoup(response_content,features="xml")
    a_tag_list = parser.find_all("a")
    for a_tag in a_tag_list:
        href = a_tag.get("href")
        join_url = urljoin(url,href)
        if "#" in join_url:
            join_url = join_url.split("#")[1]
        if target_url in join_url and join_url not in link:
            link.append(join_url)
            print(join_url)
            extract_links(join_url)


extract_links(target_url)

